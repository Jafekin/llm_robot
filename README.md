# Robotic task planning agent programme using LLM
# 基于LLM的机器人任务规划代理

> 机器人ROS操作系统大作业

## 项目简介
本项目探索了大语言模型（LLM）在家庭服务机器人任务规划中的可行性与优势。系统基于 ROS 2 构建，以 TurtleBot4 为实验平台，结合视觉感知、状态服务、导航建图与自然语言任务编排，实现机器人在真实家庭场景中的自主任务执行。核心思路是利用 ChatGPT4o 将用户的自然语言指令转换为可执行的任务计划，并在运行过程中融合环境感知与状态反馈，闭环验证规划的有效性。

## 系统架构
- **LLM 任务规划代理**：使用 ChatGPT4o 解析用户需求，生成分步任务计划与操作指令。
- **视觉与感知**：在 TurtleBot4 上部署 YOLOv8 + 深度相机，完成物体检测、定位与语义标注。
- **状态服务**：维护环境内物体的位姿、类别及状态信息，向上层规划模块提供查询接口。
- **导航与探索**：利用 ROS 2 导航栈构建初始地图，并通过探索服务在未知区域进行自主搜索。
- **房间分割与命名**：采用经典计算机视觉算法对房间进行分割，通过 LLM 生成语义化房间标签。

## 主要成果
1. 成功在 ROS 2 + TurtleBot4 平台上部署并运行全流程实验，包括感知、状态管理、规划、执行与评估。
2. YOLOv8 与深度相机融合，实现对家庭场景物体的检测、定位与类别区分。
3. 构建状态服务，可实时记录、跟踪物体位置，提供多种查询接口以支持任务规划与执行监控。
4. 借助 ChatGPT4o 根据自然语言指令生成任务计划，实现“寻找并取回指定物品”等复杂任务的执行。
5. 导航与建图模块完成环境初始建模，并通过探索服务帮助机器人在未知区域自主扩展地图。
6. 设计房间分割与命名流程，通过视觉算法划分区域，再由 LLM 生成符合人类认知的房间名称。
7. 多轮实验验证 LLM 在复杂任务规划中的有效性，为家庭、医疗及工业场景的机器人应用提供新的研究方向。

## 代码结构
项目主体位于 `ros_ws/src/` 下，关键组成如下：
- `planner/`：LLM 任务规划代理、提示词与计划执行逻辑。
- `llm/`、`interpreter_pkg/`：对接外部 LLM 服务、解析自然语言任务。
- `yolobot_recognition/`、`yolov8_msgs/`：YOLOv8 推理节点与消息定义。
- `robot/`、`fetch_description/`、`autonomous_tb3/`：机器人模型、描述文件与仿真配置。
- `litterbug/`、`room_segmentation/`：地图、房间分割脚本与相关资源。

## 快速开始
1. **环境准备**
   - 安装 ROS 2 (Humble/rolling) 及必要依赖。
   - 在 `envs/install.bash` 中配置所需依赖后运行：
     ```bash
     source envs/install.bash
     ```
2. **构建工作空间**
   ```bash
   cd ros_ws
   colcon build
   source install/setup.bash
   ```
3. **运行仿真/实机**
   - 启动 Gazebo/真实 TurtleBot4 与视觉管线。
   - 启动状态服务与任务规划节点。
   - 通过自然语言指令调用 LLM 规划代理，观察机器人执行全过程。

## 未来展望
- 引入多模态传感器与记忆机制，提升长时任务的稳健性。
- 扩展至多机器人协作与人机协同场景。
- 探索在医疗、工业等领域的定制化任务模板与安全约束。

欢迎贡献与讨论，共同推进 LLM 驱动的机器人任务规划研究。
